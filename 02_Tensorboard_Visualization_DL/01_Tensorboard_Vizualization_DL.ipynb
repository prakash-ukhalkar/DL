{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TensorBoard Introduction using MNIST Handwritten Digits Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook will demonstrate how to use TensorBoard to visualize the training process of a neural network. \n",
    "\n",
    "* We will train a model on the classic [MNIST dataset of handwritten digits](https://www.tensorflow.org/datasets/catalog/mnist), which is a perfect real-world example for beginners in computer vision and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What are Callbacks?**\n",
    "\n",
    "* Before we begin, it is crucial to understand callbacks. \n",
    "\n",
    "* Callbacks are special functions in Keras that are executed at different stages of the training process, such as at the beginning or end of an epoch or a batch. \n",
    "\n",
    "* They are a powerful mechanism for customizing the behavior of your model during training without modifying the model's code itself.\n",
    "\n",
    "* TensorBoard relies on a specific callback, `tf.keras.callbacks.TensorBoard`, to automatically log events and data that the tool can then visualize. \n",
    "\n",
    "* This callback enables you to track metrics like `loss` and `accuracy`, visualize the `model graph`, and even see how weights and biases change over time.\n",
    "\n",
    "* The `TensorBoard` callback has several key parameters:\n",
    "\n",
    "  * `log_dir`: Specifies the directory where the logs will be stored. It's a good practice to use a timestamped directory to organize different training runs.\n",
    "\n",
    "  * `histogram_freq`: Controls how often to compute histograms of the model's weights, biases, and activations. Setting it to 1, for instance, will log these histograms every epoch.\n",
    "\n",
    "  * `write_graph`: If set to `True`, it visualizes the model architecture in TensorBoard's \"Graphs\" tab.\n",
    "\n",
    "  * `write_images`: If set to `True`, it can visualize model weights as images.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup and Data Loading\n",
    "\n",
    "* We'll start by importing the necessary libraries and loading the MNIST dataset. \n",
    "\n",
    "* The MNIST database contains 60,000 training images and 10,000 testing images of handwritten digits (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset and split into training and testing sets\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the shapes of the datasets\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 5')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the first training image and its label\n",
    "plt.matshow(X_train[0])\n",
    "plt.title(f\"Label: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Preprocessing\n",
    "\n",
    "* The MNIST images are `28x28` pixels with grayscale values from `0` to `255`. \n",
    "\n",
    "* We need to normalize these pixel values to be between `0` and `1` for optimal model performance. \n",
    "\n",
    "* We will also reshape the data to a `1D vector` (784 features) since our simple model expects a flat input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Reshape the data to a 1D vector (784 features)\n",
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the shapes of the datasets after flattening\n",
    "X_train_flattened.shape, y_train.shape, X_test_flattened.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Building the Neural Network Model\n",
    "\n",
    "* We will create a simple `Sequential` model with one hidden layer. \n",
    "\n",
    "* The `Flatten` layer is a convenient way to automatically convert our 28x28 image input into a 1D array, eliminating the need for manual reshaping. \n",
    "\n",
    "* We'll then add a `Dense` hidden layer with 100 neurons and a final `Dense` output layer with 10 neurons, one for each digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compiling the Model and Setting up the TensorBoard Callback\n",
    "\n",
    "* We compile the model with an `adam` optimizer and `sparse_categorical_crossentropy` loss. \n",
    "\n",
    "* We also define our `TensorBoard` callback, specifying the log directory and `histogram_freq=1` to log weight and bias distributions every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model and Setting up the TensorBoard Callback\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define log directory for TensorBoard with timestamp\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Set up TensorBoard callback\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training the Model with the TensorBoard Callback\n",
    "\n",
    "* Finally, we train the model and pass our `tb_callback` to the `callbacks` argument of the `model.fit` method. \n",
    "\n",
    "* This will automatically generate the logs TensorBoard needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0165 - val_accuracy: 0.9792 - val_loss: 0.0783\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0149 - val_accuracy: 0.9770 - val_loss: 0.0841\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0110 - val_accuracy: 0.9796 - val_loss: 0.0814\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0109 - val_accuracy: 0.9781 - val_loss: 0.0873\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0090 - val_accuracy: 0.9769 - val_loss: 0.0976\n"
     ]
    }
   ],
   "source": [
    "# Training the Model with the TensorBoard Callback and Logging\n",
    "# Store training history in a variable for potential future use \n",
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "* Based on the training log, here are the key insights into the model's performance:\n",
    "\n",
    "  * **Excellent Training Performance**: The model learns very effectively on the training data. \n",
    "    * The training accuracy starts high at 99.51% in the first epoch and steadily improves to 99.73% by the fifth epoch. \n",
    "    * Simultaneously, the training loss consistently decreases from 0.0165 to 0.0090, indicating the model is becoming increasingly confident and accurate on the data it has seen.\n",
    "\n",
    "  * **Signs of Overfitting**: \n",
    "    * While the model performs exceptionally well on the training set, its performance on the validation set tells a different story. \n",
    "    * The validation accuracy is high (around 97.7% - 97.9%) but does not show a clear upward trend. \n",
    "    * More importantly, the validation loss increases consistently from 0.0783 in the first epoch to 0.0976 in the final epoch.\n",
    "    * The combination of decreasing training loss and increasing validation loss is a classic indicator of overfitting. \n",
    "\n",
    "* The model is starting to memorize the training data rather than learning to generalize to new, unseen examples. \n",
    "\n",
    "* This suggests that further training beyond the fifth epoch might not improve the model's ability to classify new digits and could even degrade its performance on the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Launching TensorBoard\n",
    "\n",
    "* After training, you can launch TensorBoard to view the visualizations. \n",
    "\n",
    "* If you are in a Jupyter Notebook or Google Colab, you can use the magic command below. \n",
    "\n",
    "* Alternatively, you can run `tensorboard --logdir logs/fit` from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard and point it to the log directory\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Deep Learning - Python Notebook* by [*Prakash Ukhalkar*](https://github.com/prakash-ukhalkar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
